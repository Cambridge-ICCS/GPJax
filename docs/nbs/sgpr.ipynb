{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe6a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1a5163",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Regression\n",
    "\n",
    "In this notebook we consider sparse Gaussian process regression (SGPR) Titsias 2009. This is a solution for medium- to large-scale conjugate regression problems. \n",
    "In order to arrive at a computationally tractable method, the approximate posterior is parameterized via a set of $m$ pseudo-points \\boldsymbol{z}. Critically, the approach leads to $\\mathcal{O}(nm^2)$ complexity for approximate maximum likelihood learning and $O(m^2)$ per test point for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee78ab0d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import matplotlib.pyplot as plt\n",
    "import optax as ox\n",
    "from jax import jit\n",
    "\n",
    "import gpjax as gpx\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "key = jr.PRNGKey(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3311b8e4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Dataset\n",
    "\n",
    "With the necessary modules imported, we simulate a dataset $\\mathcal{D} = (\\boldsymbol{x}, \\boldsymbol{y}) = \\{(x_i, y_i)\\}_{i=1}^{500}$ with inputs $\\boldsymbol{x}$ sampled uniformly on $(-3., 3)$ and corresponding independent noisy outputs\n",
    "\n",
    "$$\\boldsymbol{y} \\sim \\mathcal{N} \\left(\\sin(7\\boldsymbol{x}) + x \\cos(2 \\boldsymbol{x}), \\textbf{I} * 0.5^2 \\right).$$\n",
    "\n",
    "We store our data $\\mathcal{D}$ as a GPJax `Dataset` and create test inputs and labels for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81632404",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "n = 500\n",
    "noise = .5\n",
    "\n",
    "x = jr.uniform(key=key, minval=-1.0, maxval=1.0, shape=(n,)).sort().reshape(-1, 1)\n",
    "f = lambda x: jnp.sin(7 * x) + x * jnp.cos(2 * x)\n",
    "signal = f(x)\n",
    "y = signal + jr.normal(key, shape=signal.shape) * noise\n",
    "\n",
    "D = gpx.Dataset(X=x, y=y)\n",
    "\n",
    "xtest = jnp.linspace(-1.1, 1.1, 500).reshape(-1, 1)\n",
    "ytest = f(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa5634",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "To better understand what we have simulated, we plot both the underlying latent function and the observed data that is subject to Gaussian noise. We also plot an initial set of inducing points over the space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e7302c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "z = jnp.linspace(-1.0, 1.0, 20).reshape(-1, 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(xtest, ytest, label=\"Latent function\")\n",
    "ax.plot(x, y, \"o\", color=\"red\",  alpha=.8, label=\"Observations\", markersize=2.5)\n",
    "[ax.axvline(x=z_i, color=\"black\", alpha=0.3, linewidth=1) for z_i in z]\n",
    "ax.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b904331",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Next we define the posterior model for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db45d1bf",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "kernel = gpx.RBF()\n",
    "likelihood = gpx.Gaussian(num_datapoints=D.n)\n",
    "prior = gpx.Prior(kernel=kernel)\n",
    "p = prior * likelihood\n",
    "# ## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f2dd73",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We now define the SGPR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e01985",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = gpx.CollapsedVariationalGaussian(prior=prior, inducing_inputs=z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c012e543",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We define our variational inference algorithm through `CollapsedVI`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9151c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgpr = gpx.CollapsedVI(posterior=p, variational_family=q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44d1abd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We now train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a3a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, trainables, constrainers, unconstrainers = gpx.initialise(sgpr)\n",
    "\n",
    "loss_fn = jit(sgpr.elbo(D, constrainers, negative=True))\n",
    "\n",
    "optimiser = ox.adam(learning_rate=0.01)\n",
    "\n",
    "params = gpx.transform(params, unconstrainers)\n",
    "\n",
    "learned_params = gpx.fit(\n",
    "    objective = loss_fn,\n",
    "    params = params,\n",
    "    trainables = trainables,\n",
    "    optax_optim = optimiser,\n",
    "    n_iters=2000,\n",
    ")\n",
    "learned_params = gpx.transform(learned_params, constrainers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0800f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit gpx.fit(objective = loss_fn, params = params, trainables = trainables, optax_optim = optimiser,n_iters=2000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgpr.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299f8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow\n",
    "\n",
    "m = gpflow.models.SGPR(\n",
    "    data=(D.X, D.y), kernel=gpflow.kernels.SquaredExponential(), inducing_variable=z\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, trainables, constrainers, unconstrainers = gpx.initialise(sgpr)\n",
    "\n",
    "loss_fn = jit(sgpr.elbo(D, constrainers, negative=True))\n",
    "\n",
    "optimiser = ox.adam(learning_rate=0.01)\n",
    "\n",
    "params = gpx.transform(params, unconstrainers)\n",
    "\n",
    "loss_fn(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb5962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5.elbo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33449dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3994bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpflow.models import maximum_log_likelihood_objective, training_loss_closure\n",
    "\n",
    "\n",
    "opt = gpflow.optimizers.Scipy()\n",
    "loss_closure = training_loss_closure(m, (D.X, D.y))\n",
    "opt.minimize(\n",
    "    loss_closure,\n",
    "    variables=m.trainable_variables,\n",
    "    compile=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b690a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.elbo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcf1e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = m5.predict_f(xtest)\n",
    "\n",
    "a - q(D, sgpr.params)(xtest).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bfc284",
   "metadata": {},
   "outputs": [],
   "source": [
    "a - q(D, sgpr.params)(xtest).mean().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3917419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow as gpfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19179782",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpfl.models.sgpr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf458e1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We show predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dist = q.predict(D, learned_params)(xtest)\n",
    "predictive_dist = likelihood(latent_dist, learned_params)\n",
    "\n",
    "samples = latent_dist.sample(seed=key,sample_shape=20)\n",
    "\n",
    "predictive_mean = predictive_dist.mean()\n",
    "predictive_std = predictive_dist.stddev()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "ax.plot(x, y, \"o\", label=\"Observations\", color=\"tab:red\", alpha=0.8, markersize=2.5)\n",
    "ax.plot(xtest, predictive_mean, label=\"Predictive mean\", color=\"black\")\n",
    "\n",
    "ax.fill_between(xtest.squeeze(), predictive_mean - predictive_std,\n",
    "    predictive_mean + predictive_std, alpha=0.2, color=\"tab:blue\", label='Two sigma')\n",
    "ax.plot(xtest, predictive_mean - predictive_std, color=\"tab:blue\", linestyle=\"--\", linewidth=1)\n",
    "ax.plot(xtest, predictive_mean + predictive_std, color=\"tab:blue\", linestyle=\"--\", linewidth=1)\n",
    "ax.plot(xtest, ytest, label=\"Latent function\",color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "\n",
    "ax.plot(xtest, samples.T, color='tab:blue', alpha=0.8, linewidth=0.2)\n",
    "[\n",
    "    ax.axvline(x=z_i, color=\"black\", alpha=0.3, linewidth=1)\n",
    "    for z_i in learned_params[\"variational_family\"][\"inducing_inputs\"]\n",
    "]\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2104665",
   "metadata": {},
   "source": [
    "## System configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29e8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -n -u -v -iv -w -a 'Daniel Dodd'"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "custom_cell_magics": "kql"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
