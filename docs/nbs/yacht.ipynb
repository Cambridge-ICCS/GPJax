{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gpjax as gpx\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import jit\n",
    "import optax as ox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yacht = pd.read_fwf('https://archive.ics.uci.edu/ml/machine-learning-databases/00243/yacht_hydrodynamics.data', header=None).values[:-1, :]\n",
    "X = yacht[:, :-1]\n",
    "y = yacht[:, -1].reshape(-1, 1)\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ytr = np.log(ytr)\n",
    "log_yte = np.log(yte)\n",
    "y_scaler = StandardScaler().fit(log_ytr)\n",
    "scaled_y = y_scaler.transform(log_ytr)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(16, 4))\n",
    "ax[0].hist(ytr, bins=30)\n",
    "ax[0].set_title('y')\n",
    "ax[1].hist(log_ytr, bins=30)\n",
    "ax[1].set_title('log(y)')\n",
    "ax[2].hist(scaled_y, bins=30)\n",
    "ax[2].set_title('scaled log(y)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = StandardScaler().fit(Xtr)\n",
    "scaled_Xtr = x_scaler.transform(Xtr)\n",
    "scaled_Xte = x_scaler.transform(Xte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xte, ytr, yte = train_test_split(scaled_X, scaled_y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting\n",
    "\n",
    "### Model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_covariates = Xtr.shape\n",
    "kernel = gpx.kernels.RBF(active_dims = list(range(n_covariates)))\n",
    "prior = gpx.Prior(kernel = kernel)\n",
    "\n",
    "likelihood = gpx.Gaussian(num_datapoints=n_train)\n",
    "\n",
    "posterior = prior * likelihood\n",
    "\n",
    "params, trainables, constrainers, unconstrainers = gpx.initialise(posterior)\n",
    "params = gpx.transform(params, unconstrainers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = gpx.Dataset(X = Xtr, y=ytr)\n",
    "\n",
    "mll = jit(posterior.marginal_log_likelihood(train_data = training_data, transformations=constrainers, negative=True))\n",
    "learned_params = gpx.fit(objective=mll, params=params, trainables=trainables, optax_optim=ox.adam(0.05), n_iters=1000, log_rate=50)\n",
    "learned_params = gpx.transform(learned_params, constrainers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lognormal_transform(mean, variance):\n",
    "    mu = jnp.exp(mean + variance/2)\n",
    "    sigma2 = (jnp.exp(variance) - 1) * jnp.exp(2*mean + variance)\n",
    "    return mu, sigma2 \n",
    "\n",
    "latent_dist = posterior(training_data, learned_params)(Xte)\n",
    "predictive_dist = likelihood(latent_dist, learned_params)\n",
    "\n",
    "predictive_mean = predictive_dist.mean()\n",
    "predictive_variance = predictive_dist.variance()\n",
    "\n",
    "predictive_mean, predictive_variance = lognormal_transform(predictive_mean, predictive_variance)\n",
    "predictive_mean = y_scaler.inverse_transform(predictive_mean.reshape(-1, 1))\n",
    "predictive_variance = y_scaler.inverse_transform(predictive_variance.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_true = yte, y_pred = predictive_mean.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(predictive_mean.squeeze(), yte)\n",
    "ax.plot([0, 1], [0, 1], color='tab:orange', transform=ax.transAxes)\n",
    "ax.set(xlabel='Predicted', ylabel='Actual', title='Predicted vs Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('gpjax')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "920091140e6b97de16b405af485d142952a229f5dad61a888f46227f5acb94cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
