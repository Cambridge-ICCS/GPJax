{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca74b0bd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Pathwise Sampling for Spatial Modelling\n",
    "In this notebook, we demonstrate an application of Gaussian Processes\n",
    "to a spatial interpolation problem. We will show how\n",
    "to efficiently sample from a GP posterior as shown in <strong data-cite=\"wilson2020efficient\"></strong>.\n",
    "\n",
    "## Data loading\n",
    "We'll use open-source data from\n",
    "[SwissMetNet](https://www.meteoswiss.admin.ch/services-and-publications/applications/measurement-values-and-measuring-networks.html#lang=en&param=messnetz-automatisch),\n",
    "the surface weather monitoring network of the Swiss national weather service,\n",
    "and digital elevation model (DEM) data from Copernicus, accessible\n",
    "[here](https://planetarycomputer.microsoft.com/dataset/cop-dem-glo-90)\n",
    "via the Planetary Computer data catalog.\n",
    "We will coarsen this data by a factor of 10 (going from 90m to 900m resolution), but feel free to change this.\n",
    "\n",
    "Our variable of interest is the maximum daily temperature, observed on the 4th of April 2023 at\n",
    "150 weather stations, and we'll try to interpolate it on a spatial grid using geographical coordinates\n",
    "(latitude and longitude) and elevation as input variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff18c6",
   "metadata": {},
   "source": [
    "## Installation on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b5437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git clone https://github.com/Cambridge-ICCS/GPJax\n",
    "cd GPJax\n",
    "git checkout sumschool-setup\n",
    "pip install .[docs]\n",
    "pip install planetary_computer==0.5.1 \n",
    "pip install rioxarray==0.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2cff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('matplotlib').setLevel(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234d4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd GPJax/docs/examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7736a627",
   "metadata": {},
   "source": [
    "## Pathwise sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f33d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Float64 for more stable matrix inversions.\n",
    "from jax.config import config\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import fsspec\n",
    "import geopandas as gpd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "from jaxtyping import (\n",
    "    Array,\n",
    "    Float,\n",
    "    install_import_hook,\n",
    ")\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import optax as ox\n",
    "import pandas as pd\n",
    "import planetary_computer\n",
    "import pystac_client\n",
    "import rioxarray as rio\n",
    "from rioxarray.merge import merge_arrays\n",
    "import xarray as xr\n",
    "\n",
    "with install_import_hook(\"gpjax\", \"beartype.beartype\"):\n",
    "    import gpjax as gpx\n",
    "    from gpjax.base import param_field\n",
    "    from gpjax.dataset import Dataset\n",
    "\n",
    "\n",
    "key = jr.PRNGKey(123)\n",
    "plt.style.use(\"./gpjax.mplstyle\")\n",
    "cols = mpl.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "# Observed temperature data\n",
    "try:\n",
    "    temperature = pd.read_csv(\"data/max_tempeature_switzerland.csv\")\n",
    "except FileNotFoundError:\n",
    "    temperature = pd.read_csv(\"docs/examples/data/max_tempeature_switzerland.csv\")\n",
    "\n",
    "temperature = gpd.GeoDataFrame(\n",
    "    temperature,\n",
    "    geometry=gpd.points_from_xy(temperature.longitude, temperature.latitude),\n",
    ").dropna(how=\"any\")\n",
    "\n",
    "# Country borders shapefile\n",
    "path = \"simplecache::https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_admin_0_countries.zip\"\n",
    "with fsspec.open(path) as file:\n",
    "    ch_shp = gpd.read_file(file).query(\"ADMIN == 'Switzerland'\")\n",
    "\n",
    "\n",
    "# Read DEM data and clip it to switzerland\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")\n",
    "search = catalog.search(collections=[\"cop-dem-glo-90\"], bbox=[5.5, 45.5, 10.0, 48.5])\n",
    "items = list(search.get_all_items())\n",
    "tiles = [rio.open_rasterio(i.assets[\"data\"].href).squeeze().drop(\"band\") for i in items]\n",
    "dem = merge_arrays(tiles).coarsen(x=10, y=10).mean().rio.clip(ch_shp[\"geometry\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35ec6a1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Let us take a look at the data. The topography of Switzerland is quite complex, and there\n",
    "are sometimes very large height differences over short distances. This measuring network is fairly dense,\n",
    "and you may already notice that there's a dependency between maximum daily temperature and elevation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56889ad",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5), layout=\"constrained\")\n",
    "dem.plot(\n",
    "    cmap=\"terrain\", cbar_kwargs={\"aspect\": 50, \"pad\": 0.02, \"label\": \"Elevation [m]\"}\n",
    ")\n",
    "temperature.plot(\"t_max\", ax=ax, cmap=\"RdBu_r\", vmin=-15, vmax=15, edgecolor=\"k\", s=50)\n",
    "ax.set(title=\"Switzerland's topography and SwissMetNet stations\", aspect=\"auto\")\n",
    "cb = fig.colorbar(ax.collections[-1], aspect=50, pad=0.02)\n",
    "cb.set_label(\"Max. daily temperature [°C]\", labelpad=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ca352",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "As always, we store our training data in a `Dataset` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf9933",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = temperature[[\"latitude\", \"longitude\", \"elevation\"]].values\n",
    "y = temperature[[\"t_max\"]].values\n",
    "D = Dataset(\n",
    "    X=jnp.array(x),\n",
    "    y=jnp.array(y),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc777e2",
   "metadata": {},
   "source": [
    "## ARD Kernel\n",
    "As temperature decreases with height\n",
    "(at a rate of approximately -6.5 °C/km in average conditions), we can expect that using the geographical distance\n",
    "alone isn't enough to to a decent job at interpolating this data. Therefore, we can also use elevation and optimize\n",
    "the parameters of our kernel such that more relevance should be given to elevation. This is possible by using a\n",
    "kernel that has one length-scale parameter per input dimension: an automatic relevance determination (ARD) kernel.\n",
    "See our [kernel notebook](https://docs.jaxgaussianprocesses.com/examples/kernels/) for more an introduction to\n",
    "kernels in GPJax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd99ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = gpx.kernels.RBF(\n",
    "    active_dims=[0, 1, 2],\n",
    "    lengthscale=jnp.array([0.1, 0.1, 100.0]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6da89d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Mean function\n",
    "As stated before, we already know that temperature strongly depends on elevation.\n",
    "So why not use it for our mean function? GPJax lets you define custom mean functions;\n",
    "simply subclass `AbstractMeanFunction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092a0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MeanFunction(gpx.gps.AbstractMeanFunction):\n",
    "    w: Float[Array, \"1\"] = param_field(jnp.array([0.0]))\n",
    "    b: Float[Array, \"1\"] = param_field(jnp.array([0.0]))\n",
    "\n",
    "    def __call__(self, x: Float[Array, \"N D\"]) -> Float[Array, \"N 1\"]:\n",
    "        elevation = x[:, 2:3]\n",
    "        out = elevation * self.w + self.b\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d98ca7",
   "metadata": {},
   "source": [
    "Now we can define our prior. We'll also choose a Gaussian likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_function = MeanFunction()\n",
    "prior = gpx.Prior(kernel=kernel, mean_function=mean_function)\n",
    "likelihood = gpx.Gaussian(D.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016639b4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Finally, we construct the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e62e22",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "posterior = prior * likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e38a6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Model fitting\n",
    "We proceed to train our model. Because we used a Gaussian likelihood, the resulting posterior is\n",
    "a `ConjugatePosterior`, which allows us to optimize the analytically expressed marginal loglikelihood.\n",
    "\n",
    "As always, we can jit-compile the objective function to speed things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa9a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_mll = jax.jit(gpx.objectives.ConjugateMLL(negative=True))\n",
    "negative_mll(posterior, train_data=D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a02df7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "optim = ox.chain(ox.adam(learning_rate=0.1), ox.clip(1.0))\n",
    "posterior, history = gpx.fit(\n",
    "    model=posterior,\n",
    "    objective=negative_mll,\n",
    "    train_data=D,\n",
    "    optim=optim,\n",
    "    num_iters=3000,\n",
    "    safe=True,\n",
    "    key=key,\n",
    ")\n",
    "posterior: gpx.gps.ConjugatePosterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217568f4",
   "metadata": {},
   "source": [
    "## Sampling on a grid\n",
    "Now comes the cool part. In a standard GP implementation, for n test points, we have a $\\mathcal{O}(n^2)$\n",
    "computational complexity and $\\mathcal{O}(n^2)$ memory requirement. We want to make predictions on a total\n",
    "of roughly 70'000 pixels, and that would require us to compute a covariance matrix of `70000 ** 2 = 4900000000` elements.\n",
    "If these are `float64`s, as it is often the case in GPJax, it would be equivalent to more than 36 Gigabytes of memory. And\n",
    "that's for a fairly coarse and tiny grid. If we were to make predictions on a 1000x1000 grid, the total memory required\n",
    "would be 8 _Terabytes_ of memory, which is intractable.\n",
    "Fortunately, the pathwise conditioning method allows us to sample from our posterior in linear complexity,\n",
    "$\\mathcal{O}(n)$, with the number of pixels.\n",
    "\n",
    "GPJax provides the `sample_approx` method to generate random conditioned samples from our posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3013ce",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# select the target pixels and exclude nans\n",
    "xtest = dem.drop(\"spatial_ref\").stack(p=[\"y\", \"x\"]).to_dataframe(name=\"dem\")\n",
    "mask = jnp.any(jnp.isnan(xtest.values), axis=-1)\n",
    "\n",
    "# generate 50 samples\n",
    "ytest = posterior.sample_approx(50, D, key, num_features=200)(\n",
    "    jnp.array(xtest.values[~mask])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52efc4",
   "metadata": {},
   "source": [
    "Let's take a look at the results. We start with the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b0800",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "predtest = xr.zeros_like(dem.stack(p=[\"y\", \"x\"])) * jnp.nan\n",
    "predtest[~mask] = ytest.mean(axis=-1)\n",
    "predtest = predtest.unstack()\n",
    "\n",
    "predtest.plot(\n",
    "    vmin=-15.0,\n",
    "    vmax=15.0,\n",
    "    cmap=\"RdBu_r\",\n",
    "    cbar_kwargs={\"aspect\": 50, \"pad\": 0.02, \"label\": \"Max. daily temperature [°C]\"},\n",
    ")\n",
    "plt.gca().set_title(\"Interpolated maximum daily temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed7afb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "predtest = xr.zeros_like(dem.stack(p=[\"y\", \"x\"])) * jnp.nan\n",
    "predtest[~mask] = ytest.std(axis=-1)\n",
    "predtest = predtest.unstack()\n",
    "\n",
    "# plot\n",
    "predtest.plot(\n",
    "    cbar_kwargs={\"aspect\": 50, \"pad\": 0.02, \"label\": \"Standard deviation [°C]\"},\n",
    ")\n",
    "plt.gca().set_title(\"Standard deviation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd31eb96",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "And now some individual realizations of our GP posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d1cbd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "predtest = (\n",
    "    xr.zeros_like(dem.stack(p=[\"y\", \"x\"]))\n",
    "    .expand_dims(realization=range(9))\n",
    "    .transpose(\"p\", \"realization\")\n",
    "    .copy()\n",
    ")\n",
    "predtest[~mask] = ytest[:, :9]\n",
    "predtest = predtest.unstack()\n",
    "predtest.plot(\n",
    "    col=\"realization\",\n",
    "    col_wrap=3,\n",
    "    cbar_kwargs={\"aspect\": 50, \"pad\": 0.02, \"label\": \"Max. daily temperature [°C]\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce2fcf1",
   "metadata": {},
   "source": [
    "Remember when we said that on average the temperature decreases with height at a rate\n",
    "of approximately -6.5°C/km? That's -0.0065°C/m. The `w` parameter of our mean function\n",
    "is very close: we have learned the environmental lapse rate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90042c2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "print(posterior.prior.mean_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3fefae",
   "metadata": {},
   "source": [
    "That's it! We've successfully interpolated an observed meteorological parameter on a grid.\n",
    "We have used several components of GPJax and adapted them to our needs: a custom mean function\n",
    "that modelled the average temperature lapse rate; an ARD kernel that learned to give more relevance\n",
    "to elevation rather than horizontal distance; an efficient sampling technique to produce\n",
    "probabilistic realizations of our posterior on a large number of test points, which is important for\n",
    "many spatiotemporal modelling applications.\n",
    "If you're interested in a more elaborate work on temperature interpolation for the same domain used here, refer\n",
    "to [Frei 2014](https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/joc.3786)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb6474",
   "metadata": {},
   "source": [
    "## System configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97332f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -n -u -v -iv -w -a 'Francesco Zanetta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777c94d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "custom_cell_magics": "kql",
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
