{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24ef0249",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "In this notebook we demonstate how to fit a Gaussian process regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84e5eeb",
   "metadata": {},
   "source": [
    "# Installation on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65a606bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'GPJax'...\n",
      "Switched to a new branch 'sumschool-setup'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 'sumschool-setup' set up to track remote branch 'sumschool-setup' from 'origin'.\n",
      "Processing /home/ubuntu/GPJax/docs/examples/GPJax\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: gpjax-0.0.0.post1048.dev0-0325d53 0.0.0.post1048.dev0+0325d53 does not provide the extra 'docs'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beartype<0.14.0,>=0.13.1 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from gpjax==0.0.0.post1048.dev0+0325d53) (0.13.1)\n",
      "Requirement already satisfied: orbax-checkpoint<0.3.0,>=0.2.0 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from gpjax==0.0.0.post1048.dev0+0325d53) (0.2.3)\n",
      "Requirement already satisfied: optax<0.2.0,>=0.1.4 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from gpjax==0.0.0.post1048.dev0+0325d53) (0.1.5)\n",
      "Requirement already satisfied: jax>=0.4.1 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from gpjax==0.0.0.post1048.dev0+0325d53) (0.4.13)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from gpjax==0.0.0.post1048.dev0+0325d53) (4.65.0)\n",
      "Requirement already satisfied: simple-pytree<0.2.0,>=0.1.7 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from gpjax==0.0.0.post1048.dev0+0325d53) (0.1.7)\n",
      "Requirement already satisfied: plum-dispatch<3.0.0,>=2.1.0 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from gpjax==0.0.0.post1048.dev0+0325d53) (2.1.1)\n",
      "Collecting jaxlib==0.4.7\n",
      "  Using cached jaxlib-0.4.7-cp38-cp38-manylinux2014_x86_64.whl (66.1 MB)\n",
      "Requirement already satisfied: tensorflow-probability<0.20.0,>=0.19.0 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from gpjax==0.0.0.post1048.dev0+0325d53) (0.19.0)\n",
      "Requirement already satisfied: jaxtyping<0.3.0,>=0.2.15 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from gpjax==0.0.0.post1048.dev0+0325d53) (0.2.19)\n",
      "Requirement already satisfied: msgpack in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from orbax-checkpoint<0.3.0,>=0.2.0->gpjax==0.0.0.post1048.dev0+0325d53) (1.0.5)\n",
      "Requirement already satisfied: importlib_resources in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from orbax-checkpoint<0.3.0,>=0.2.0->gpjax==0.0.0.post1048.dev0+0325d53) (5.12.0)\n",
      "Requirement already satisfied: nest_asyncio in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from orbax-checkpoint<0.3.0,>=0.2.0->gpjax==0.0.0.post1048.dev0+0325d53) (1.5.6)\n",
      "Requirement already satisfied: absl-py in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from orbax-checkpoint<0.3.0,>=0.2.0->gpjax==0.0.0.post1048.dev0+0325d53) (1.4.0)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from orbax-checkpoint<0.3.0,>=0.2.0->gpjax==0.0.0.post1048.dev0+0325d53) (6.0)\n",
      "Requirement already satisfied: typing_extensions in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from orbax-checkpoint<0.3.0,>=0.2.0->gpjax==0.0.0.post1048.dev0+0325d53) (4.7.1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from orbax-checkpoint<0.3.0,>=0.2.0->gpjax==0.0.0.post1048.dev0+0325d53) (1.24.4)\n",
      "Requirement already satisfied: cached_property in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from orbax-checkpoint<0.3.0,>=0.2.0->gpjax==0.0.0.post1048.dev0+0325d53) (1.5.2)\n",
      "Requirement already satisfied: etils in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from orbax-checkpoint<0.3.0,>=0.2.0->gpjax==0.0.0.post1048.dev0+0325d53) (1.3.0)\n",
      "Requirement already satisfied: tensorstore>=0.1.35 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from orbax-checkpoint<0.3.0,>=0.2.0->gpjax==0.0.0.post1048.dev0+0325d53) (0.1.40)\n",
      "Requirement already satisfied: chex>=0.1.5 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from optax<0.2.0,>=0.1.4->gpjax==0.0.0.post1048.dev0+0325d53) (0.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=4.6; python_version < \"3.10\" in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from jax>=0.4.1->gpjax==0.0.0.post1048.dev0+0325d53) (6.7.0)\n",
      "Requirement already satisfied: opt-einsum in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from jax>=0.4.1->gpjax==0.0.0.post1048.dev0+0325d53) (3.3.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from jax>=0.4.1->gpjax==0.0.0.post1048.dev0+0325d53) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from jax>=0.4.1->gpjax==0.0.0.post1048.dev0+0325d53) (1.10.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from tensorflow-probability<0.20.0,>=0.19.0->gpjax==0.0.0.post1048.dev0+0325d53) (1.16.0)\n",
      "Requirement already satisfied: dm-tree in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from tensorflow-probability<0.20.0,>=0.19.0->gpjax==0.0.0.post1048.dev0+0325d53) (0.1.8)\n",
      "Requirement already satisfied: gast>=0.3.2 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from tensorflow-probability<0.20.0,>=0.19.0->gpjax==0.0.0.post1048.dev0+0325d53) (0.5.4)\n",
      "Requirement already satisfied: decorator in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from tensorflow-probability<0.20.0,>=0.19.0->gpjax==0.0.0.post1048.dev0+0325d53) (5.1.1)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from tensorflow-probability<0.20.0,>=0.19.0->gpjax==0.0.0.post1048.dev0+0325d53) (2.2.1)\n",
      "Requirement already satisfied: typeguard>=2.13.3 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from jaxtyping<0.3.0,>=0.2.15->gpjax==0.0.0.post1048.dev0+0325d53) (4.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from importlib_resources->orbax-checkpoint<0.3.0,>=0.2.0->gpjax==0.0.0.post1048.dev0+0325d53) (3.15.0)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /home/ubuntu/GPJax/venv/lib/python3.8/site-packages (from chex>=0.1.5->optax<0.2.0,>=0.1.4->gpjax==0.0.0.post1048.dev0+0325d53) (0.12.0)\n",
      "Building wheels for collected packages: gpjax\n",
      "  Building wheel for gpjax (PEP 517): started\n",
      "  Building wheel for gpjax (PEP 517): finished with status 'done'\n",
      "  Created wheel for gpjax: filename=gpjax-0.0.0.post1048.dev0+0325d53-py3-none-any.whl size=101594 sha256=fd30b129eb8bd7cc310f3aae3244a4b8ebf056cbfba3ed97a7194f5c1549e6cb\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4s4qseci/wheels/a7/5b/bd/6cb4699dd4f3bb3a2a5f7bb5f2272e55fd21b5928a88b952d3\n",
      "Successfully built gpjax\n",
      "Installing collected packages: jaxlib, gpjax\n",
      "  Attempting uninstall: jaxlib\n",
      "    Found existing installation: jaxlib 0.4.11\n",
      "    Uninstalling jaxlib-0.4.11:\n",
      "      Successfully uninstalled jaxlib-0.4.11\n",
      "  Attempting uninstall: gpjax\n",
      "    Found existing installation: gpjax 0.0.0\n",
      "    Uninstalling gpjax-0.0.0:\n",
      "      Successfully uninstalled gpjax-0.0.0\n",
      "Successfully installed gpjax-0.0.0.post1048.dev0+0325d53 jaxlib-0.4.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 5: cd: ./GPJax/docs/examples: No such file or directory\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'git clone https://github.com/Cambridge-ICCS/GPJax\\ncd GPJax\\ngit checkout sumschool-setup\\npip install .[docs]\\ncd ./GPJax/docs/examples \\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgit clone https://github.com/Cambridge-ICCS/GPJax\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mcd GPJax\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mgit checkout sumschool-setup\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mpip install .[docs]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mcd ./GPJax/docs/examples \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GPJax/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2478\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2477\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2478\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/GPJax/venv/lib/python3.8/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GPJax/venv/lib/python3.8/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'git clone https://github.com/Cambridge-ICCS/GPJax\\ncd GPJax\\ngit checkout sumschool-setup\\npip install .[docs]\\ncd ./GPJax/docs/examples \\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git clone https://github.com/Cambridge-ICCS/GPJax\n",
    "cd GPJax\n",
    "git checkout sumschool-setup\n",
    "pip install .[docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd9f1f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/GPJax/docs/examples/GPJax/docs/examples\n"
     ]
    }
   ],
   "source": [
    "cd GPJax/docs/examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae3c767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "jaxlib is version 0.4.7, but this version of jax requires version >= 0.4.11.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Enable Float64 for more stable matrix inversions.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m      4\u001b[0m config\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjax_enable_x64\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jit\n",
      "File \u001b[0;32m~/GPJax/venv/lib/python3.8/site-packages/jax/__init__.py:35\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _cloud_tpu_init\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Confusingly there are two things named \"config\": the module and the class.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# We want the exported object to be the class, so we first import the module\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# to make sure a later import doesn't overwrite the class.\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config \u001b[38;5;28;01mas\u001b[39;00m _config_module\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _config_module\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Force early import, allowing use of `jax.core` after importing `jax`.\u001b[39;00m\n",
      "File \u001b[0;32m~/GPJax/venv/lib/python3.8/site-packages/jax/config.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2018 The JAX Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# TODO(phawkins): fix users of this alias and delete this file.\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/GPJax/venv/lib/python3.8/site-packages/jax/_src/config.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, List, Callable, Hashable, NamedTuple, Iterator, Optional\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jax_jit\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transfer_guard_lib\n",
      "File \u001b[0;32m~/GPJax/venv/lib/python3.8/site-packages/jax/_src/lib/__init__.py:73\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _jaxlib_version\n\u001b[1;32m     72\u001b[0m version_str \u001b[38;5;241m=\u001b[39m jaxlib\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39m__version__\n\u001b[0;32m---> 73\u001b[0m version \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_jaxlib_version\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjax_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjaxlib_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjaxlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m  \u001b[49m\u001b[43mminimum_jaxlib_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_minimum_jaxlib_version\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Before importing any C compiled modules from jaxlib, first import the CPU\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# feature guard module to verify that jaxlib was compiled in a way that only\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# uses instructions that are present on this machine.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjaxlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcpu_feature_guard\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcpu_feature_guard\u001b[39;00m\n",
      "File \u001b[0;32m~/GPJax/venv/lib/python3.8/site-packages/jax/_src/lib/__init__.py:62\u001b[0m, in \u001b[0;36mcheck_jaxlib_version\u001b[0;34m(jax_version, jaxlib_version, minimum_jaxlib_version)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _jaxlib_version \u001b[38;5;241m<\u001b[39m _minimum_jaxlib_version:\n\u001b[1;32m     60\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjaxlib is version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjaxlib_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but this version \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     61\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mof jax requires version >= \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminimum_jaxlib_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _jaxlib_version \u001b[38;5;241m>\u001b[39m _jax_version:\n\u001b[1;32m     65\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjaxlib version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjaxlib_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is newer than and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     66\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincompatible with jax version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjax_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     67\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdate your jax and/or jaxlib packages.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: jaxlib is version 0.4.7, but this version of jax requires version >= 0.4.11."
     ]
    }
   ],
   "source": [
    "# Enable Float64 for more stable matrix inversions.\n",
    "from jax.config import config\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from jax import jit\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "from jaxtyping import install_import_hook\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import optax as ox\n",
    "from utils import clean_legend\n",
    "\n",
    "with install_import_hook(\"gpjax\", \"beartype.beartype\"):\n",
    "    import gpjax as gpx\n",
    "\n",
    "key = jr.PRNGKey(123)\n",
    "plt.style.use(\"./gpjax.mplstyle\")\n",
    "cols = mpl.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaefb02c",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "With the necessary modules imported, we simulate a dataset\n",
    "$\\mathcal{D} = (\\boldsymbol{x}, \\boldsymbol{y}) = \\{(x_i, y_i)\\}_{i=1}^{100}$ with inputs $\\boldsymbol{x}$\n",
    "sampled uniformly on $(-3., 3)$ and corresponding independent noisy outputs\n",
    "\n",
    "$$\\boldsymbol{y} \\sim \\mathcal{N} \\left(\\sin(4\\boldsymbol{x}) + \\cos(2 \\boldsymbol{x}), \\textbf{I} * 0.3^2 \\right).$$\n",
    "\n",
    "We store our data $\\mathcal{D}$ as a GPJax `Dataset` and create test inputs and labels\n",
    "for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ca638",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "noise = 0.3\n",
    "\n",
    "key, subkey = jr.split(key)\n",
    "x = jr.uniform(key=key, minval=-3.0, maxval=3.0, shape=(n,)).reshape(-1, 1)\n",
    "f = lambda x: jnp.sin(4 * x) + jnp.cos(2 * x)\n",
    "signal = f(x)\n",
    "y = signal + jr.normal(subkey, shape=signal.shape) * noise\n",
    "\n",
    "D = gpx.Dataset(X=x, y=y)\n",
    "\n",
    "xtest = jnp.linspace(-3.5, 3.5, 500).reshape(-1, 1)\n",
    "ytest = f(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb2ea9",
   "metadata": {},
   "source": [
    "To better understand what we have simulated, we plot both the underlying latent\n",
    "function and the observed data that is subject to Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca0330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, \"o\", label=\"Observations\", color=cols[0])\n",
    "ax.plot(xtest, ytest, label=\"Latent function\", color=cols[1])\n",
    "ax.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07133d04",
   "metadata": {},
   "source": [
    "Our aim in this tutorial will be to reconstruct the latent function from our noisy\n",
    "observations $\\mathcal{D}$ via Gaussian process regression. We begin by defining a\n",
    "Gaussian process prior in the next section.\n",
    "\n",
    "## Defining the prior\n",
    "\n",
    "A zero-mean Gaussian process (GP) places a prior distribution over real-valued\n",
    "functions $f(\\cdot)$ where\n",
    "$f(\\boldsymbol{x}) \\sim \\mathcal{N}(0, \\mathbf{K}_{\\boldsymbol{x}\\boldsymbol{x}})$\n",
    "for any finite collection of inputs $\\boldsymbol{x}$.\n",
    "\n",
    "Here $\\mathbf{K}_{\\boldsymbol{x}\\boldsymbol{x}}$ is the Gram matrix generated by a\n",
    "user-specified symmetric, non-negative definite kernel function $k(\\cdot, \\cdot')$\n",
    "with $[\\mathbf{K}_{\\boldsymbol{x}\\boldsymbol{x}}]_{i, j} = k(x_i, x_j)$.\n",
    "The choice of kernel function is critical as, among other things, it governs the\n",
    "smoothness of the outputs that our GP can generate.\n",
    "\n",
    "For simplicity, we consider a radial basis function (RBF) kernel:\n",
    "$$k(x, x') = \\sigma^2 \\exp\\left(-\\frac{\\lVert x - x' \\rVert_2^2}{2 \\ell^2}\\right).$$\n",
    "\n",
    "On paper a GP is written as $f(\\cdot) \\sim \\mathcal{GP}(\\textbf{0}, k(\\cdot, \\cdot'))$,\n",
    "we can reciprocate this process in GPJax via defining a `Prior` with our chosen `RBF`\n",
    "kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ff38a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = gpx.kernels.RBF()\n",
    "meanf = gpx.mean_functions.Zero()\n",
    "prior = gpx.Prior(mean_function=meanf, kernel=kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225a8ddf",
   "metadata": {},
   "source": [
    "\n",
    "The above construction forms the foundation for GPJax's models. Moreover, the GP prior\n",
    "we have just defined can be represented by a\n",
    "[TensorFlow Probability](https://www.tensorflow.org/probability/api_docs/python/tfp/substrates/jax)\n",
    "multivariate Gaussian distribution. Such functionality enables trivial sampling, and\n",
    "the evaluation of the GP's mean and covariance ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a177fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_dist = prior.predict(xtest)\n",
    "\n",
    "prior_mean = prior_dist.mean()\n",
    "prior_std = prior_dist.variance()\n",
    "samples = prior_dist.sample(seed=key, sample_shape=(20,))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(xtest, samples.T, alpha=0.5, color=cols[0], label=\"Prior samples\")\n",
    "ax.plot(xtest, prior_mean, color=cols[1], label=\"Prior mean\")\n",
    "ax.fill_between(\n",
    "    xtest.flatten(),\n",
    "    prior_mean - prior_std,\n",
    "    prior_mean + prior_std,\n",
    "    alpha=0.3,\n",
    "    color=cols[1],\n",
    "    label=\"Prior variance\",\n",
    ")\n",
    "ax.legend(loc=\"best\")\n",
    "ax = clean_legend(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996bd1fd",
   "metadata": {},
   "source": [
    "## Constructing the posterior\n",
    "\n",
    "Having defined our GP, we proceed to define a description of our data\n",
    "$\\mathcal{D}$ conditional on our knowledge of $f(\\cdot)$ --- this is exactly the\n",
    "notion of a likelihood function $p(\\mathcal{D} | f(\\cdot))$. While the choice of\n",
    "likelihood is a critical in Bayesian modelling, for simplicity we consider a\n",
    "Gaussian with noise parameter $\\alpha$\n",
    "$$p(\\mathcal{D} | f(\\cdot)) = \\mathcal{N}(\\boldsymbol{y}; f(\\boldsymbol{x}), \\textbf{I} \\alpha^2).$$\n",
    "This is defined in GPJax through calling a `Gaussian` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ddbf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpx.Gaussian(num_datapoints=D.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5554cab9",
   "metadata": {},
   "source": [
    "The posterior is proportional to the prior multiplied by the likelihood, written as\n",
    "\n",
    "  $$ p(f(\\cdot) | \\mathcal{D}) \\propto p(f(\\cdot)) * p(\\mathcal{D} | f(\\cdot)). $$\n",
    "\n",
    "Mimicking this construct, the posterior is established in GPJax through the `*` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9383639",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = prior * likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8306e3",
   "metadata": {},
   "source": [
    "<!-- ## Hyperparameter optimisation\n",
    "\n",
    "Our kernel is parameterised by a length-scale $\\ell^2$ and variance parameter\n",
    "$\\sigma^2$, while our likelihood controls the observation noise with $\\alpha^2$.\n",
    "Using Jax's automatic differentiation module, we can take derivatives of  -->\n",
    "\n",
    "## Parameter state\n",
    "\n",
    "As outlined in the [PyTrees](https://jax.readthedocs.io/en/latest/pytrees.html)\n",
    "documentation, parameters are contained within the model and for the leaves of the\n",
    "PyTree. Consequently, in this particular model, we have three parameters: the\n",
    "kernel lengthscale, kernel variance and the observation noise variance. Whilst\n",
    "we have initialised each of these to 1, we can learn Type 2 MLEs for each of\n",
    "these parameters by optimising the marginal log-likelihood (MLL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a007f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "negative_mll = gpx.objectives.ConjugateMLL(negative=True)\n",
    "negative_mll(posterior, train_data=D)\n",
    "\n",
    "\n",
    "# static_tree = jax.tree_map(lambda x: not(x), posterior.trainables)\n",
    "# optim = ox.chain(\n",
    "#     ox.adam(learning_rate=0.01),\n",
    "#     ox.masked(ox.set_to_zero(), static_tree)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f153432",
   "metadata": {},
   "source": [
    "For researchers, GPJax has the capacity to print the bibtex citation for objects such\n",
    "as the marginal log-likelihood through the `cite()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a2b9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpx.cite(negative_mll))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc91d70",
   "metadata": {},
   "source": [
    "JIT-compiling expensive-to-compute functions such as the marginal log-likelihood is\n",
    "advisable. This can be achieved by wrapping the function in `jax.jit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7011fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_mll = jit(negative_mll)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28fc137",
   "metadata": {},
   "source": [
    "Since most optimisers (including here) minimise a given function, we have realised\n",
    "the negative marginal log-likelihood and just-in-time (JIT) compiled this to\n",
    "accelerate training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8e5bae",
   "metadata": {},
   "source": [
    "We can now define an optimiser with `optax`. For this example we'll use the `adam`\n",
    "optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7269b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_posterior, history = gpx.fit(\n",
    "    model=posterior,\n",
    "    objective=negative_mll,\n",
    "    train_data=D,\n",
    "    optim=ox.adam(learning_rate=0.01),\n",
    "    num_iters=500,\n",
    "    safe=True,\n",
    "    key=key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55339daf",
   "metadata": {},
   "source": [
    "The calling of `fit` returns two objects: the optimised posterior and a history of\n",
    "training losses. We can plot the training loss to see how the optimisation has\n",
    "progressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(history, color=cols[1])\n",
    "ax.set(xlabel=\"Training iteration\", ylabel=\"Negative marginal log likelihood\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00eeb0c",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Equipped with the posterior and a set of optimised hyperparameter values, we are now\n",
    "in a position to query our GP's predictive distribution at novel test inputs. To do\n",
    "this, we use our defined `posterior` and `likelihood` at our test inputs to obtain\n",
    "the predictive distribution as a `Distrax` multivariate Gaussian upon which `mean`\n",
    "and `stddev` can be used to extract the predictive mean and standard deviatation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dist = opt_posterior.predict(xtest, train_data=D)\n",
    "predictive_dist = opt_posterior.likelihood(latent_dist)\n",
    "\n",
    "predictive_mean = predictive_dist.mean()\n",
    "predictive_std = predictive_dist.stddev()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886464b2",
   "metadata": {},
   "source": [
    "With the predictions and their uncertainty acquired, we illustrate the GP's\n",
    "performance at explaining the data $\\mathcal{D}$ and recovering the underlying\n",
    "latent function of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280409f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7.5, 2.5))\n",
    "ax.plot(x, y, \"x\", label=\"Observations\", color=cols[0], alpha=0.5)\n",
    "ax.fill_between(\n",
    "    xtest.squeeze(),\n",
    "    predictive_mean - 2 * predictive_std,\n",
    "    predictive_mean + 2 * predictive_std,\n",
    "    alpha=0.2,\n",
    "    label=\"Two sigma\",\n",
    "    color=cols[1],\n",
    ")\n",
    "ax.plot(\n",
    "    xtest,\n",
    "    predictive_mean - 2 * predictive_std,\n",
    "    linestyle=\"--\",\n",
    "    linewidth=1,\n",
    "    color=cols[1],\n",
    ")\n",
    "ax.plot(\n",
    "    xtest,\n",
    "    predictive_mean + 2 * predictive_std,\n",
    "    linestyle=\"--\",\n",
    "    linewidth=1,\n",
    "    color=cols[1],\n",
    ")\n",
    "ax.plot(\n",
    "    xtest, ytest, label=\"Latent function\", color=cols[0], linestyle=\"--\", linewidth=2\n",
    ")\n",
    "ax.plot(xtest, predictive_mean, label=\"Predictive mean\", color=cols[1])\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(0.975, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c7bc1b",
   "metadata": {},
   "source": [
    "## System configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -n -u -v -iv -w -a 'Thomas Pinder & Daniel Dodd'"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "custom_cell_magics": "kql"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
